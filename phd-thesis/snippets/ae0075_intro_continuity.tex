\section*{Introduction, problem formulation, and positioning}

Adaptive high-order CFD (spectral/\(hp\) element methods) is compelling because it can deliver accuracy efficiently by concentrating numerical effort where the physics demands it.
In practice, that concentration changes over time: near-wall layers, wakes, and shear regions evolve, and the simulation must continually re-distribute where it spends computational effort.

In high-order element methods, “resolution” is controlled not only by element size \(h\), but also by polynomial degree \(P\).
When adaptivity changes the spatial distribution of \(P\) (and sometimes \(h\)), the compute cost becomes strongly nonuniform.
At scale, this matters because many timestep phases include synchronization or globally coupled solves, so end-to-end wall time is throttled by the slowest rank/device.

This proposal targets the following decision problem on heterogeneous CPU/GPU clusters:
given an adaptive simulation whose cost distribution changes over time, \emph{when} should repartitioning/migration be performed, and \emph{how much} state should be moved, in order to reduce wall time without creating churn?
Periodic policies (rebalance every \(k\)) are simple but can pay overhead in regimes where the mapping changes weakly, including no-op or near-no-op events.
Triggered policies are only useful if they can reliably predict whether a rebalance will be net-positive.

We therefore evaluate policies using phase-aware wall-time metrics and explicit overhead accounting.
Key quantities include timestep wall time \(t_{\text{step}}\), imbalance ratio \(\rho=\max/\text{mean}\), effective efficiency \(\eta\approx \text{mean}/\max\), the number of rebalance events (and no-ops), and migration intensity (elements moved and migration time).
A policy is “better” only if it reduces end-to-end wall time while keeping overhead bounded and preserving solution acceptability (QoI tolerance).

The algorithmic foundation is spectral element and spectral/\(hp\) CFD (e.g., \cite{Patera1984SpectralElement,KarniadakisSherwin2005}), with Nektar++ as the target platform (e.g., \cite{Cantwell2015NektarPP,Cantwell2020NektarPP}).
The gap we focus on is not whether load balancing exists, but rather the combination of (i) superlinear cost growth with \(P\), (ii) explicit modeling of rebalance overhead, and (iii) heterogeneity-aware decision rules that avoid wasted rebalances and migration churn.

Our preliminary results already show signals consistent with this gap: strong superlinear cost growth with order, hotspot-driven imbalance, solver-phase dominance at scale, and the promise of triggered policies to reduce unnecessary events.
These observations motivate a model-driven trigger rule and bounded migration as the central research lever.

The remainder of this proposal formalizes the benefit–cost decision model, defines the trigger and migration bounds, and lays out an evaluation plan designed to produce publishable, phase-aware performance evidence.
