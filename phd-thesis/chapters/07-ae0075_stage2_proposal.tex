\providecommand{\code}[1]{\texttt{#1}}
\makeatletter
\@ifundefined{path}{\providecommand{\codepath}[1]{\texttt{#1}}}{\providecommand{\codepath}[1]{\path{#1}}}
\makeatother
\markboth{}{}

% detokenize removed
\providecommand{\AEQCoverMode}{0}
% AE0075 Stage-2 Proposal (Draft v2)
% Contract: No invented achievements. No invented quotes. Use labels EXACTLY:
% VERIFIED / UNKNOWN / UNVERIFIED / ASSUMED

% AE0075_ONLY: suppressed mini-cover heading

% 
% AE0075_ONLY: suppressed mini-title
%\section*{AE0075 Stage-2 Research Proposal (Draft)}

% (counter suppressed)% (counter suppressed)% (toc entry suppressed)
% ===================== SUBMISSION-POLISH PATCH BEGIN =====================
% Identity / metadata
\ifnum\AEQCoverMode=0\relax
\begin{center}
{\Large \textbf{AE0075 Stage-2 Research Proposal}}\\[0.4em]
{\normalsize \textit{Studentship title: TBD (paste verbatim from Imperial listing)}}\\[0.8em]
{\large \textbf{Mason Shopperly}}\\
{\normalsize \today}
\end{center}
\fi

\vspace{0.5em}

\input{snippets/ae0075_exec_summary.tex}
\input{snippets/ae0075_intro_continuity.tex}
\input{snippets/ae0075_aims_eval.tex}

% ====================== SUBMISSION-POLISH PATCH END ======================

\label{ch:ae0075}
% (toc entry suppressed)

% --- labels (EXACT strings) ---
\newcommand{\VERIFIED}{\textbf{VERIFIED}}
\newcommand{\UNKNOWN}{\textbf{UNKNOWN}}
\newcommand{\UNVERIFIED}{\textbf{UNVERIFIED}}
\newcommand{\ASSUMED}{\textbf{ASSUMED}}

% --- claim/evidence hooks ---
\newcommand{\Claim}[1]{\textbf{[Claim #1]}}
\newcommand{\Evidence}[1]{\textit{Evidence: #1}}
\newcommand{\Reproduce}[1]{\texttt{Reproduce: #1}}

% Breakable monospace paths (prevents overfull hbox spam)
% DUPLICATE codepath removed
% Keep ugly draft readable while we iterate
\begingroup
\sloppy

\endgroup

% === AE0075 WORLD-CLASS ADDENDUM START ===
\clearpage

% === AE0075_PRELIM_RESULTS_START ===

\section{Preliminary results and evidence base}
\label{sec:ae0075-prelim}



\noindent This section summarizes what is already quantified in the current Nektar++ Cylinder2D runs, and the specific measurements we add next to extend the same analysis to MPI, heterogeneity, and a QoI tolerance.
\vspace{0.4em}
\noindent\textit{Measured anchor (Cylinder2D).} Timestep cost grows strongly and superlinearly with order. A compact fit captures the observed scaling:
\[
\text{ms/step} \approx k\,P^{a}.
\]
The current calibrated parameters are:

\begin{center}
\begin{tabular}{lccc}
\hline
Dataset & $k$ & $a$ & $r^2$ \\
\hline
Re=100 (primary) & 0.223522 & 2.682 & 0.9985 \\
Re=40 (secondary) & 0.315049 & 2.467 & 0.9962 \\
\hline
\end{tabular}
\end{center}

\noindent This is the starting point for time-based weights when \(P\) varies in space: equal element counts do not imply equal time.

\vspace{0.4em}
\noindent\textit{Grounded offline signal (hotspot imbalance).} Using the measured fit above as element weights, clustered high-\(P\) regions create concentrated cost that a count-based partition can co-locate. In a clustered ``wake-like'' ordering with contiguous partitions, the resulting naive max/mean imbalance ratios are on the order of $\approx 2.7$--$4.0$ (offline demo grounded by the measured fit).

\vspace{0.4em}
\noindent\textit{Grounded offline signal (policy behavior).} In regime sweeps with explicit migration penalty, fixed-cadence schedules can spend rebalance events on no-op or near-no-op remaps (0 elements moved), and that wasted fraction is cadence-sensitive. A triggered policy removes no-op events across sweeps and can match periodic performance with fewer rebalance calls in near-crossover regimes (e.g., \(40\rightarrow 18\) events).

\vspace{0.4em}
\noindent\textit{What we measure next (commitments).} The next runs add the missing decision terms directly: (i) per-rank (and device) time distributions in MPI to confirm slowest-partition throttling, (ii) overhead decomposition for repartition+migration+rebuild, and (iii) a QoI definition with a tolerance so ``faster'' remains valid.

% === AE0075_PRELIM_RESULTS_END ===





\section{Execution credibility (measured evidence + reproducible artifacts)}

\textbf{Evidence discipline.} Every non-trivial performance claim below corresponds to a tracked artifact under \texttt{supplementary material (available on request)} (or is explicitly marked \textbf{ASSUMED} / \textbf{UNVERIFIED} pending verification). This proposal is intentionally ``measurement-first'' and self-policing.

\vspace{0.5em}
\noindent\textbf{What is already measured (and re-runnable):}
\begin{itemize}
 \item \textbf{Measured p-scaling fit (real Nektar++ Cylinder2D):} ms/step $\approx k \cdot P^{a}$ with $(k,a,r^2)$ recorded for Re=100 primary. Reproduce: \texttt{bash runs/cylinder2d/p\_sweep.sh}. Output: \texttt{p\_sweep\_re100.csv}.
 \item \textbf{Trigger vs periodic:} event-driven trigger removes wasted no-op rebalances and can match periodic performance with fewer events (e.g., 40 $\rightarrow$ 18 rebalances in a near-crossover regime). Backed by tracked comparison CSVs and summarized in \texttt{key\_results.md}.
 \item \textbf{Timer composition:} global solves dominate Execute time, motivating solve-aware rebalancing rather than naive element-count balancing.
 \item \textbf{Heterogeneity sensitivity:} effective efficiency can collapse sharply under controlled slowdowns, motivating heterogeneity-aware weighting and bounded migration.
\end{itemize}

% AE0075_EVAL_TABLE_V2_START
\begin{table}[H]
\centering
\small
\setlength{\tabcolsep}{5pt}
\renewcommand{\arraystretch}{1.18}
% AE0075_EVAL_MATRIX_V2_START
\begin{tabular}{p{0.26\linewidth} p{0.26\linewidth} p{0.33\linewidth} p{0.10\linewidth}}
\toprule
\textbf{Question} & \textbf{Metric(s)} & \textbf{Evidence (tracked)} & \textbf{Status} \\
\midrule
P-cost superlinear in \(P\)? &
fit params \(k,a,r^2\) &
\codepath{p\_sweep\_re100.csv} (fit via \codepath{runs/cylinder2d/pack\_tables.py}) &
\textbf{MEASURED} \\
Clustered hp hotspots cause imbalance? &
max/mean, mean/max &
\codepath{imbalance\_demo\_clustered.csv} (grounded in measured fit) &
\textbf{MODELED} \\
Global solves dominate at scale? &
(Pressure+Viscous)/Execute &
\codepath{cylinder2d\_timer\_profile\_p3p6\_fin20\_v2.csv} &
\textbf{MEASURED} \\
Heterogeneity collapses effective efficiency? &
effective efficiency vs baseline &
\codepath{cylinder2d\_mpi\_hetero\_amp\_p6\_fin20\_r3\_summary.csv} &
\textbf{MEASURED} \\
Trigger reduces no-op rebalances? &
events, moved\_elems\_total, avg\_ms &
\codepath{rebalance\_trade\_regime\_*cmp\_trigger*\_re100.csv} &
\textbf{MODELED} \\
QoI invariant under rebalance? &
QoI drift tolerance &
\textit{Define QoI + measure on at least one adaptive case (next).} &
\textbf{ASSUMED} \\
\bottomrule
\end{tabular}
% AE0075_EVAL_MATRIX_V2_END

\caption{Evaluation matrix (clean layout; targets are fixed once portal constraints and QoI are defined).}
\end{table}
% AE0075_EVAL_TABLE_V2_END

\clearpage
% AE0075_TECH_APPROACH_START
\clearpage
\section{Technical Approach: Triggered Rebalancing with Bounded Migration}

\noindent\textbf{Objective.} Replace periodic ``rebalance every $k$'' with a \emph{cost--benefit trigger} and a \emph{migration budget} so rebalancing happens only when it is predicted to reduce time-to-solution more than it costs (coordination + data movement), and never induces unstable churn.

\subsection*{A. Performance model (measured, then used for decisions)}
We decompose per-step time as
\[
T_{\text{step}} \;\approx\; T_{\text{compute}}(P,\text{elem}) \;+\; T_{\text{comm}}(\partial\Omega,\text{messages}) \;+\; T_{\text{solve}}(\text{global}).
\]
\begin{itemize}
 \item \textbf{Compute:} use a calibrated per-element cost model, with a strong prior that cost grows superlinearly with local polynomial order \(P\). (Calibration inputs: p-sweep CSVs.)
 \item \textbf{Communication:} model as a function of cut edges / message counts / bytes; keep it simple initially (linear fit) and refine only if it materially changes decisions.
 \item \textbf{Global solve sensitivity:} incorporate the measured dominance of global solves at scale as an explicit term so that rebalancing decisions are not blind to the true bottleneck.
\end{itemize}

\subsection*{B. Imbalance and predicted benefit}
Let \(t_r\) be the modeled per-step time contribution for rank (or device) \(r\). Define an imbalance ratio
\[
\rho \;=\; \frac{\max_r t_r}{\mathrm{mean}_r\, t_r},
\qquad \text{and an efficiency proxy}\qquad
\eta \approx \frac{1}{\rho}.
\]
A candidate remap \(M\rightarrow M'\) yields a predicted improvement
\[
\Delta T_{\text{benefit}} \;\approx\; T_{\text{step}}(M)\;-\;T_{\text{step}}(M').
\]
\textbf{Key point:} \(\Delta T_{\text{benefit}}\) is computed from the calibrated model, so it can be evaluated cheaply and repeatedly across adaptation steps.

\subsection*{C. Trigger rule (rebalance only when it is worth it)}
We rebalance when predicted savings exceed predicted overhead:
\[
\textbf{Trigger if}\quad \Delta T_{\text{benefit}} \;>\; \gamma\, T_{\text{overhead}},
\]
where \(T_{\text{overhead}} = T_{\text{coord}} + T_{\text{migrate}} + T_{\text{rebuild}}\) and \(\gamma\ge 1\) is a safety margin (tuned by robustness sweeps).
\begin{itemize}
 \item \textbf{Coordination:} barrier + partition computation + metadata exchange.
 \item \textbf{Migration:} element/DOF transfer + field remap cost (see bounded migration below).
 \item \textbf{Rebuild:} communication pattern rebuild and any solver-side reinitialization.
\end{itemize}

\subsection*{D. Bounded migration (prevent churn; match heterogeneous constraints)}
A pure trigger can still choose aggressive remaps. We enforce a budget:
\[
\textbf{moved\_cost}(M\rightarrow M') \;\le\; B,
\]
where \(\textbf{moved\_cost}\) is \emph{not} just ``moved elements''. A stronger proxy (target for implementation) is \textbf{P-weighted DOFs moved} (or an equivalent \(hp\)-aware measure). This aligns the migration penalty with what actually dominates runtime and bandwidth.

\subsection*{E. Algorithm sketch (decision loop)}
\begin{enumerate}
 \item After each adapt step, compute per-rank modeled costs \(t_r\) and current imbalance \(\rho\).
 \item Propose a candidate remap \(M'\) using heterogeneity-aware weights (WP2) under budget \(B\).
 \item Compute \(\Delta T_{\text{benefit}}\) and \(T_{\text{overhead}}\).
 \item If \(\Delta T_{\text{benefit}} > \gamma T_{\text{overhead}}\), apply remap; else skip.
 \item Log: predicted vs realized \(T_{\text{step}}\), overhead, and any mismatch to refine the model.
\end{enumerate}

\subsection*{F. What this achieves (why it solves more than “it’s a problem”)}
\begin{itemize}
 \item \textbf{No-op elimination:} if the remap is predicted not to help, it is not executed.
 \item \textbf{Overhead control:} the budget \(B\) bounds worst-case data movement and rebuild churn.
 \item \textbf{Heterogeneity awareness:} weights encode device/rank speed so ``balanced'' means balanced in \emph{time}, not element count.
 \item \textbf{Measurable progress:} each component (model fit, trigger threshold, migration budget) is validated via tracked CSV sweeps and regenerated tables/plots.
\end{itemize}

\noindent\textbf{Reproduce (UNVERIFIED path until wired):} add a single driver script that (i) runs a param sweep over \(\gamma\) and \(B\), (ii) emits tracked CSVs, and (iii) regenerates the proposal tables/figures from those CSVs.
% AE0075_TECH_APPROACH_END

\section{Research plan (work packages + crisp deliverables)}

\subsection*{WP0 --- Evidence harness and reproducibility (continuous)}
\begin{itemize}
 \item Maintain one-command doc rebuild and keep all headline numbers generated from tracked CSVs.
 \item Deliverable: \texttt{key\_results.md} remains numbers-first source of truth.
\end{itemize}

\subsection*{WP1 --- Nektar++ hook points (feasibility mapping; Gate-2)}
\begin{itemize}
 \item Identify where element work / polynomial order / timers expose imbalance signals.
 \item Identify where repartition + migration can be inserted in an adaptive loop.
 \item Deliverable: \texttt{NEKTARPP\_HOOKS.md} with file paths + entry points (\textbf{UNVERIFIED} until Nektar++ source is in-scope here).
\end{itemize}

\subsection*{WP2 --- Static heterogeneity-aware weighting}
\begin{itemize}
 \item Extend weights to account for rank-speed model + solver-phase dominance (solve-aware weighting).
 \item Evaluate on controlled slowdown perturbations and report net wall-time and efficiency.
\end{itemize}

\subsection*{WP3 --- Dynamic rebalancing (trigger + bounded migration)}
\begin{itemize}
 \item Trigger policy: rebalance only when predicted loss exceeds threshold (no wasted events).
 \item Bounded migration: cap moved units per adapt step; study crossover vs heterogeneity and hotspot severity.
 \item Deliverable: stability of throughput under adaptation with explicitly bounded overhead.
\end{itemize}

\clearpage
\section{Timeline (36 months, with gates and “done means”)}

\begin{table}[H]
\centering
\small
\begin{tabular}{p{0.18\linewidth} p{0.76\linewidth}}
\toprule
Window & Outcomes (each line ends in a concrete artifact) \\
\midrule
Months 1--3 &
WP0 finalize + WP1 hook mapping; publish \texttt{NEKTARPP\_HOOKS.md} (\textbf{UNVERIFIED} until source access),
lock portal constraints, lock QoI definition, freeze metrics. \\
Months 4--9 &
WP2 static heterogeneity-aware weighting; at least one controlled-perturbation win with tracked CSV + regenerated docs. \\
Months 10--18 &
WP3 trigger + bounded migration; regime maps across heterogeneity/hotspot/adapt cadence; “no-op eliminated” robustness tables. \\
Months 19--30 &
Generalize to additional adaptive cases; refine models; draft paper-quality evaluation. \\
Months 31--36 &
Thesis write-up + final validation + dissemination. \\
\bottomrule
\end{tabular}
\caption{High-level timeline (kept honest by artifacts and gates).}
\end{table}

\input{snippets/ae0075_references.tex}

% === AE0075 WORLD-CLASS ADDENDUM END ===
